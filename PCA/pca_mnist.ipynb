{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around with PCA on MNIST data.\n",
    "stough 202-\n",
    "\n",
    "We're going look at Principal Component Analysis and the MNIST data today, and an analogy with some of the block transform and image compression stuff we've done before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import \n",
    "A lot. We need MNIST data, PCA, and all of our block transform materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For the MNIST data\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# For PCA \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from skimage.util import montage\n",
    "\n",
    "# For importing some of our own utility codes.\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "from matrix_utils import (arr_info,\n",
    "                          make_linmap)\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hists,\n",
    "                       vis_pair)\n",
    "\n",
    "from wavelet_utils import (make_haar_matrix,\n",
    "                           make_random_basis,\n",
    "                           make_klt_basis,\n",
    "                           make_dct_matrix,\n",
    "                           make_standard_matrix,\n",
    "                           vis_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Formatting the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thank you: https://www.aiworkbox.com/lessons/load-mnist-dataset-from-pytorch-torchvision\n",
    "# https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "mnist_trainset = datasets.MNIST(root='/home/dip365/data', train=True, download=False, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='/home/dip365/data', train=False, download=False, transform=None)\n",
    "\n",
    "x_train = np.stack([np.array(x).ravel() for x,_ in mnist_trainset])\n",
    "x_test = np.stack([np.array(x).ravel() for x,_ in mnist_testset])\n",
    "y_train = np.stack([y for _,y in mnist_trainset]).astype('long')\n",
    "y_test = np.stack([y for _,y in mnist_testset]).astype('long')\n",
    "\n",
    "# These are Nx784\n",
    "x_train = x_train.astype(np.float32)/255.0\n",
    "x_test = x_test.astype(np.float32)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA \n",
    "We'll do a PCA analysis of the MNIST training set to see its power on this kind of data. Let's use [pca_spanFaces](./pca_spanFaces.ipynb) as a guide. Here each row of `x_train` for example represents a $28\\times28$ image. PCA won't know anything about that, and will just think we have 60K points in a 784-D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thinking about PCA as a pattern basis,\n",
    "like we did with block transforms and image compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = make_klt_basis(np.reshape(x_train[1], (28,28)), size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_blocks(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
