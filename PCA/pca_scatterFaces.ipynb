{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA scattering of ORL Faces\n",
    "stough 202-\n",
    "\n",
    "A look at PCA to scatter the [ORL faces database](http://cam-orl.co.uk/facedatabase.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.offsetbox import (OffsetImage,\n",
    "                                  AnnotationBbox)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "NUMFACES = 20 # Number of random faces to display in the first scatterplot\n",
    "NUMSUBJECTS = 3 # Number of subjects to display in the subject-specific scatter\n",
    "\n",
    "imshape = (112, 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orl_faces = ImageFolder('/home/dip365/data/ORL/', \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Grayscale(),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Lambda(lambda x: np.array(x).ravel())\n",
    "                       ]))\n",
    "\n",
    "faces = np.stack([orl_faces[i][0] \n",
    "                  for i in np.random.choice(len(orl_faces), NUMFACES)])\n",
    "allfaces = np.stack([orl_faces[i][0] for i in range(len(orl_faces))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.shape, allfaces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get 10 most important 10304-d directions in the space of faces.\n",
    "pca = PCA(n_components=10)\n",
    "Xp = pca.fit_transform(allfaces)\n",
    "# Xp is actually 320x10 here: each of the 320 training images is now\n",
    "# projected into the 10-d pca space.\n",
    "print('Explained variation per principal component: \\n{}'.\\\n",
    "      format(pca.explained_variance_ratio_))\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(1,3, figsize=(8,3), sharey=True, sharex=True)\n",
    "f.canvas.set_window_title('Average Face and Two Pricipal Components')\n",
    "ax[0].imshow(np.reshape(allfaces.mean(axis=0), imshape), cmap='gray')\n",
    "ax[0].set_title('Average Face')\n",
    "\n",
    "# pca.components_ is 10 x 10304 here, representing the most meaningful\n",
    "# directions in the 10304-d space of face images.\n",
    "ax[1].imshow(np.reshape(pca.components_[0,:], imshape), cmap='gray')\n",
    "ax[1].set_title('PCA 1');\n",
    "\n",
    "ax[2].imshow(np.reshape(pca.components_[1,:], imshape), cmap='gray')\n",
    "ax[2].set_title('PCA 2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now scatter some random faces in the pca dimensions.\n",
    "# Xp from above is already 320 x 10, the 10-pca dimensional\n",
    "# projection of each image.\n",
    "\n",
    "# Which images to display is randomized, so that's it's different each time run.\n",
    "np.random.seed() # Comment out this line to ensure the same images are displayed each run.\n",
    "whichfaces = np.random.choice(len(allfaces), NUMFACES, replace=False)\n",
    "xys = Xp[whichfaces, :]\n",
    "\n",
    "\n",
    "f2, ax2 = plt.subplots(figsize=(5,5))\n",
    "f2.canvas.set_window_title('Face PCA Projection Scatter')\n",
    "\n",
    "\"\"\"\n",
    "How to scatter images in a plot, instead of points for example:\n",
    "https://matplotlib.org/examples/pylab_examples/demo_annotation_box.html\n",
    "Also useful:\n",
    "https://stackoverflow.com/questions/22566284/matplotlib-how-to-plot-images-instead-of-points?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa\n",
    "and:\n",
    "https://stackoverflow.com/questions/48896088/matplotlib-plotting-images-instead-of-points-stretches-images\n",
    "\"\"\"\n",
    "for i, xy in zip(whichfaces, xys):\n",
    "    arr_img = np.reshape(allfaces[i, :], imshape)\n",
    "\n",
    "    imagebox = OffsetImage(arr_img, zoom=0.4, cmap='gray')\n",
    "    imagebox.image.axes = ax2\n",
    "\n",
    "    # xy is 10-d here, just need the first 2 to plot though.\n",
    "    ab = AnnotationBbox(imagebox, xy[:2],\n",
    "                        pad=0.2,\n",
    "                        )\n",
    "\n",
    "    ax2.add_artist(ab)\n",
    "\n",
    "ax2.set_xlim(xys[:,0].min(), xys[:,0].max())\n",
    "ax2.set_ylim(xys[:,1].min(), xys[:,1].max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, scatter just NUMSUBJECTS different subjects in the space,\n",
    "# see if they cluster nicely.\n",
    "whichsubjects = np.random.choice(np.arange(1, len(orl_faces.classes)+1),\n",
    "                                 NUMSUBJECTS, replace=False)\n",
    "\n",
    "alltargets = np.stack([orl_faces[i][1] for i in range(len(orl_faces))])\n",
    "\n",
    "f3, ax3 = plt.subplots()\n",
    "\n",
    "for i, label in enumerate(alltargets):\n",
    "    if label in whichsubjects:\n",
    "        arr_img = np.reshape(allfaces[i, :], imshape)\n",
    "\n",
    "        imagebox = OffsetImage(arr_img, zoom=0.4, cmap='gray')\n",
    "        imagebox.image.axes = ax3\n",
    "\n",
    "        ab = AnnotationBbox(imagebox, Xp[i,:2],\n",
    "                            pad=0.2,\n",
    "                            )\n",
    "\n",
    "        ax3.add_artist(ab)\n",
    "\n",
    "ax3.set_xlim(Xp[:,0].min(), Xp[:,0].max())\n",
    "ax3.set_ylim(Xp[:,1].min(), Xp[:,1].max())\n",
    "plt.suptitle(f'Face PCA Scatter for Subjects {whichsubjects}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Let's add a t-sne visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ripped from: https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "mycolors = .2 + .9*np.random.rand(40,3)\n",
    "mycolors = np.clip(mycolors, 0, 1)\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(Xp)\n",
    "\n",
    "# Legend: https://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
    "import matplotlib.patches as mpatches\n",
    "patch_list = [mpatches.Patch(color=mycolors[i], label=str(i)) for i in range(len(mycolors))]\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize=(8,5))\n",
    "\n",
    "ax.scatter(tsne_results[:,0], tsne_results[:,1], c = mycolors[alltargets], alpha=.75)\n",
    "# plt.legend(handles=patch_list)\n",
    "\n",
    "# Legend positioning: https://pythonspot.com/matplotlib-legend/\n",
    "chartBox = ax.get_position()\n",
    "ax.set_position([chartBox.x0, chartBox.y0, chartBox.width*0.6, chartBox.height])\n",
    "ax.legend(handles=patch_list, loc='upper center', bbox_to_anchor=(1.35, 1.1), shadow=True, ncol=2);\n",
    "\n",
    "# plt.legend(handles=patch_list, loc='upper right', bbox_to_anchor=(1.0, 0.5), shadow=True, ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
